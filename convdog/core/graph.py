import collections
from typing import Dict, Optional
import ast
import math

import numpy as np
import onnx
from onnx import numpy_helper

from convdog.utils.logger import logger


class ConvDogGraph(object):
    def __init__(self, model_path: str):
        logger.info(f"æ­£åœ¨å—…æ¢æ¨¡å‹: [bold white]{model_path}[/]", extra={"markup": True})
        self.model = onnx.load(model_path)
        # åˆå§‹åŒ–ç´¢å¼•
        self.nodes = {}
        self.initializers: Dict[str, np.ndarray] = {}
        self.producers = {}
        self.consumers = collections.defaultdict(list)
        self.update_indexes()
        logger.info(f"æˆåŠŸå—…æ¢æ¨¡å‹: [bold white]{model_path}[/]")

    @property
    def graph(self) -> onnx.GraphProto:
        return self.model.graph

    def inject_convdog_info(self, author_name="ConvDogğŸ•"):
        """
        å‘ ONNX æ¨¡å‹ä¸­æ³¨å…¥â€œè½¬æ¢ç‹—â€ç‰¹æœ‰çš„å¯¼å‡ºä¿¡æ¯
        """
        # å‡†å¤‡å…ƒæ•°æ®å­—å…¸
        meta_info = {
            "producer_name": "ConvDogğŸ• (è½¬æ¢æ±ª)",
            "producer_version": "0.1.0",
            "description": "This model was hunted and optimized by ConvDog.",
            "author": author_name,
            "status": "Injected_For_Testing"
        }

        # æ¸…ç†æ—§çš„åŒåå…ƒæ•°æ®ï¼ˆé˜²æ­¢é‡å¤æ³¨å…¥ï¼‰
        existing_props = {prop.key for prop in self.model.metadata_props}

        for key, value in meta_info.items():
            if key not in existing_props:
                meta_prop = self.model.metadata_props.add()
                meta_prop.key = key
                meta_prop.value = value

        # [x] åŒæ—¶ä¿®æ”¹ producer å­—æ®µ
        # ä¿ç•™åŸå§‹å¯¼å‡ºä¿¡æ¯
        # self.model.producer_name = "ConvDogğŸ•"
        # self.model.producer_version = "0.1.0"

        logger.debug(f"æˆåŠŸæ³¨å…¥å…ƒæ•°æ®ï¼Œç•™ä¸‹çˆªå°ï¼š{author_name}")

    def update_indexes(self):
        """
        é‡ç½®å¹¶é‡æ–°æ„å»ºå…¨å›¾ç´¢å¼•ã€‚
        ä¿®å¤ç‚¹ï¼šç¡®ä¿ self.initializers å§‹ç»ˆå­˜å‚¨ NumPy æ•°ç»„è€Œé TensorProtoã€‚
        """
        self.nodes.clear()
        self.initializers.clear()
        self.producers.clear()
        self.consumers.clear()

        # 1. å»ºç«‹èŠ‚ç‚¹ã€ç”Ÿäº§è€…ã€æ¶ˆè´¹è€…é€»è¾‘
        for node in self.graph.node:
            if node.name:
                self.nodes[node.name] = node

            for output in node.output:
                self.producers[output] = node

            for input_name in node.input:
                self.consumers[input_name].append(node)

        # 2. ã€ä¿®å¤å…³é”®ã€‘ï¼šå»ºç«‹æƒé‡ç´¢å¼•æ—¶ï¼Œå¼ºåˆ¶è½¬æ¢ Proto ä¸º Numpy
        for init in self.graph.initializer:
            # è¿™æ ·ä¿è¯äº†å…¶ä»– Passï¼ˆå¦‚ FP16Quantizerï¼‰æ‹¿åˆ°çš„æ°¸è¿œæ˜¯ array
            self.initializers[init.name] = numpy_helper.to_array(init)

        logger.debug("å›¾ç´¢å¼•å·²åˆ·æ–°ï¼š[cyan]%d[/] èŠ‚ç‚¹, [cyan]%d[/] æƒé‡æ•°ç»„",
                     len(self.graph.node), len(self.initializers), extra={"markup": True})

    def get_initializer_array(self, name: str) -> Optional[np.ndarray]:
        """
        è·å–æƒé‡æ•°ç»„ã€‚å› ä¸ºç´¢å¼•é‡Œå­˜çš„å°±æ˜¯ Numpyï¼Œç›´æ¥è¿”å›å³å¯ã€‚
        """
        return self.initializers.get(name)

    def add_initializer(self, name: str, array: np.ndarray):
        """
        å‘å›¾ä¸­æ·»åŠ æˆ–æ›´æ–°æƒé‡ã€‚
        """
        # 1. ç”Ÿæˆåº•å±‚ Proto å¯¹è±¡ç”¨äº ONNX åºåˆ—åŒ–
        new_init = numpy_helper.from_array(array, name=name)

        # 2. åŒæ­¥æ›´æ–° ModelProto
        # ä¼˜å…ˆæŸ¥æ‰¾å¹¶æ›¿æ¢ï¼Œä¸å­˜åœ¨åˆ™è¿½åŠ 
        found = False
        for i, init in enumerate(self.graph.initializer):
            if init.name == name:
                self.graph.initializer.remove(init)
                self.graph.initializer.insert(i, new_init)
                found = True
                break
        if not found:
            self.graph.initializer.append(new_init)

        # 3. åŒæ­¥æ›´æ–°å†…éƒ¨ NumPy ç´¢å¼•
        self.initializers[name] = array

    @staticmethod
    def _parser_symbolic_shape(
            expression: str,
            symbolic_shape: Dict[str, int]
    ):
        """
        å®‰å…¨åœ°è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ï¼Œæ”¯æŒç®€å•çš„æ•°å­¦å‡½æ•°
        """

        # å®šä¹‰å…è®¸çš„æ•°å­¦å‡½æ•°
        allowed_functions = {
            'floor': math.floor,
            'ceil': math.ceil,
            'round': round,
            'sqrt': math.sqrt,
            'abs': abs,
            'int': int,
            'float': float,
            'math': math
        }
        allowed_symbols = {
            'floor': "math.floor",
            'ceil': "math.ceil",
            'round': "round",
            'sqrt': "math.sqrt",
            'abs': "abs",
            'int': "int",
            'float': "float"
        }

        for key, value in symbolic_shape.items():
            expression = expression.replace(key, str(value))
        for key, value in allowed_symbols.items():
            expression = expression.replace(key, str(value))
        expression = expression.strip()

        # 1. é¦–å…ˆå°è¯•ç›´æ¥è®¡ç®—ç®€å•è¡¨è¾¾å¼
        try:
            # ä½¿ç”¨ ast è§£æç¡®ä¿å®‰å…¨
            tree = ast.parse(expression, mode='eval')

            # æ£€æŸ¥ AST ä¸­æ˜¯å¦åªåŒ…å«å®‰å…¨çš„èŠ‚ç‚¹ç±»å‹
            safe_nodes = (
                ast.Expression, ast.BinOp, ast.UnaryOp, ast.Constant,
                ast.Add, ast.Sub, ast.Mult, ast.Div, ast.FloorDiv, ast.Mod,
                ast.Pow, ast.USub, ast.UAdd, ast.Num, ast.Constant,
                ast.Call, ast.Name, ast.Attribute, ast.Load
            )

            for node in ast.walk(tree):
                if isinstance(node, safe_nodes):
                    if isinstance(node, ast.Call):
                        # æ£€æŸ¥å‡½æ•°è°ƒç”¨æ˜¯å¦åœ¨å…è®¸åˆ—è¡¨ä¸­
                        if isinstance(node.func, ast.Name):
                            if node.func.id not in allowed_functions:
                                raise ValueError(f"ä¸å…è®¸çš„å‡½æ•°è°ƒç”¨: {node.func.id}")
                    elif isinstance(node, ast.Attribute):
                        if node.attr not in allowed_functions.keys():
                            raise ValueError(f"ä¸å®‰å…¨çš„èŠ‚ç‚¹ç±»å‹: {type(node).__name__}")
                else:
                    raise ValueError(f"ä¸å®‰å…¨çš„èŠ‚ç‚¹ç±»å‹: {type(node).__name__}")

            # ç¼–è¯‘å¹¶æ‰§è¡Œ
            code = compile(tree, '<string>', 'eval')
            result = eval(code, {"__builtins__": {}}, allowed_functions)

            if isinstance(result, (int, float)):
                return int(result)  # å½¢çŠ¶ç»´åº¦åº”è¯¥æ˜¯æ•´æ•°
        except Exception as e:
            logger.debug(e)
            logger.debug("å½¢çŠ¶æ¨æ–­å¤±è´¥!!!é€€å›åŸç¬¦å·å½¢çŠ¶")
            return symbolic_shape

    def formalize_graph(self):
        """
        å·¥ä¸šçº§å›¾è§„èŒƒåŒ–ï¼šå°†æ‰€æœ‰ Constant èŠ‚ç‚¹è½¬ä¸º Initializerã€‚
        è§£å†³ ORT ä¼˜åŒ–å™¨åœ¨å¤§æ¨¡å‹èåˆæ—¶å¯¹ Constant èŠ‚ç‚¹çš„ç´¢å¼•æŸ¥æ‰¾å¤±è´¥é—®é¢˜ã€‚
        """
        new_nodes = []
        for node in self.model.graph.node:
            if node.op_type == "Constant":
                # æå–å¸¸é‡å€¼å¹¶è½¬ä¸º Initializer
                tensor_proto = node.attribute[0].t
                tensor_proto.name = node.output[0]
                self.model.graph.initializer.append(tensor_proto)
            else:
                new_nodes.append(node)

        # é‡æ–°åˆ·æ–°èŠ‚ç‚¹åˆ—è¡¨
        self.model.graph.ClearField("node")
        self.model.graph.node.extend(new_nodes)
        self.update_indexes()

    def resize_input_shape(self, input_shapes: dict):
        """
        åº•å±‚å·¥å…·ï¼šä¿®æ”¹è¾“å…¥èŠ‚ç‚¹çš„ Proto å¹¶åˆ·æ–°å…¨å›¾å½¢çŠ¶
        """
        symbolic_shape = {}  # ç¼“å­˜ç¬¦å·å½¢çŠ¶æ˜ å°„

        for input_proto in self.model.graph.input:
            if input_proto.name in input_shapes:
                target_shape = input_shapes[input_proto.name]
                # ä¿®æ”¹ Opaque çš„ TensorTypeProto
                for i, dim in enumerate(input_proto.type.tensor_type.shape.dim):
                    if i < len(target_shape):
                        if len(dim.dim_param) > 0:
                            symbolic_shape[dim.dim_param] = target_shape[i]
                        dim.ClearField("dim_param")
                        dim.dim_value = target_shape[i]
                logger.debug(f"GraphCore: å·²ä¿®æ”¹è¾“å…¥ {input_proto.name} çš„å°ºå¯¸æ•°æ®")

        for idx, value_info in enumerate(self.graph.value_info):
            for dim in value_info.type.tensor_type.shape.dim:
                if dim.HasField("dim_param"):
                    cur_symbolic_shape = dim.dim_param
                    static_shape = self._parser_symbolic_shape(
                        cur_symbolic_shape, symbolic_shape
                    )
                    if not isinstance(static_shape, dict):
                        dim.ClearField("dim_param")
                        dim.dim_value = static_shape

        self.formalize_graph()

        # æ ¸å¿ƒæ­¥éª¤ï¼šé‡æ–°æ¨ç†å½¢çŠ¶ä»¥ç¡®ä¿ä¸­é—´ ValueInfo é€»è¾‘ä¸€è‡´
        import onnx.shape_inference
        self.model = onnx.shape_inference.infer_shapes(
            self.model,
            strict_mode=True,
            check_type=True
        )
        try:
            onnx.checker.check_model(self.model, full_check=True)
        except Exception as e:
            logger.error(e)
            logger.warning("é™æ€å›¾æ£€æŸ¥å¤±è´¥!!!")
        self.update_indexes()

    def save(self, output_path: str):
        """æ‰§è¡Œæœ€ç»ˆæ£€æŸ¥å¹¶ä¿å­˜"""
        try:
            # æ³¨æ„ï¼šä¿å­˜å‰å¦‚æœæœ‰å¤§é‡ add_initializerï¼Œå…¶å®ä¸éœ€è¦ full update_indexes
            # é™¤éä½ ä¿®æ”¹äº†èŠ‚ç‚¹çš„ input/output æ‹“æ‰‘ã€‚
            # ä¸ºäº†ä¿é™©èµ·è§ä¿ç•™å®ƒï¼Œä½†ä¹Ÿç¡®ä¿äº†å…¶ä¸­çš„è½¬æ¢é€»è¾‘æ˜¯æ­£ç¡®çš„ã€‚
            self.update_indexes()

            onnx.checker.check_model(self.model)
            onnx.save(self.model, output_path)
            logger.success(f"å¯¼å‡ºæˆåŠŸ: [underline]{output_path}[/]", extra={"markup": True})
        except Exception as e:
            logger.error(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
